<!DOCTYPE html>
<html lang="en">
<head>
	<title>Blog Page</title>
	<meta charset="utf-8">
	<link href="../style.css" rel="stylesheet" type="text/css" />
	<script type="text/x-mathjax-config">
		MathJax.Hub.Config({
			TeX: {
				extensions: ["color.js"],
				equationNumbers: { autoNumber: "AMS" },
			}
		});
	</script>
	<script language="JavaScript" type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
	<script src="https://cdn.rawgit.com/google/code-prettify/master/loader/run_prettify.js"></script>
</head>
<body id="blog">
<h1>How to formalise a goal?</h1>

<h2 id="context">Context</h2>

<p>
<!-- TODO -->
</p>

<h2 id="question">Question</h2>

<p>
<!-- TODO -->
</p>

<h2 id="method">Method</h2>

<p>
<!-- TODO -->
</p>

<h3 id="dictionary_definitions">Dictionary Definitions</h3>

<p>
<!-- TODO -->
We ignore the definitions related to sports in particular, like the goal in soccer or in a race.
- <q>Goal</q> from <a href="http://dictionary.cambridge.org/dictionary/english/goal">Cambridge Dictionaries</a>:
	- <q>an aim or purpose</q>, in other words a result that one intends to reach or the reason why one does something.
- <q>Goal</q> from <a href="https://en.oxforddictionaries.com/definition/goal">Oxford Dictionaries</a>:
	- <q>an aim or desired result</q>, concepts that the dictionary again relates to the notion of purpose (a reason why), intention, and desired outcome.
	- <q>the object of a person's ambition or effort</q>, which again relates to the desire of someone to achieve something.
- <q>Goal</q> from <a href="https://www.merriam-webster.com/dictionary/goal">Merriam-Webster</a>:
	- <q>the end toward which effort is directed</q>, as a synonym of aim, i.e. a clearly directed intent or purpose.
</p>

<h3 id="formalisation_preparation">Informal Summary Before Proper Formalisation</h3>

<p>
All these definitions link as synonyms the notions of goal, aim, and purpose, but two perspectives can be highlighted: the <em>future result</em> that one desires to produce and the <em>current reason</em> which motivates the act.
The future result put an emphasis on the future, such that we act in order to change (or maintain) the state of the world progressively towards a state that we deem as valuable.
Nervertheless, the future result does not exist at the current time (it might be already the case, but we want it to be the case in the future too), which means that we can only speak about an <em>expected</em> result, such that the action we plan to execute should, to the best of our knowledge, leads this expected result to become (or remain) true.
This is where the current reason is established: one acts based on the incentives it has at the moment of the action, and the reason why one acts can be because this action is &mdash;currently&mdash; expected to lead to a wanted future result.
If we remain loose on the interpretation of the term, other reasons could be considered, like daily routine: although thinking about it may lead to remember the future state we expect to reach through this ation, the actual incentive leading to act is the habit.
This example, and a more broader notion of <em>cause</em>, is however irrelevant in our case, because we loose the intentional aspect that goal, aim, and purpose have been defined with.
If we want to keep this intention then we may speak about trials or attempts, but again these actions can be done in order to reach a wanted future, possibly less specific, like find an answer to a question rather than proove that a particular answer is the right one, but still a wanted future.
We may speak about actions where we don't know what could be the future result of an action, like a random trial, but it seems hard to explain such an action without an automatism or an intention to reach a wanted future through evolutions we think to be probable.
In short, the main interpretation we reach when sepaking about a goal is a desired, future state of the world.<!-- TODO Cite papers about that, check RE -->
</p>

<p>
One should however not fall in the shortcut of considering a goal as a delta between the current state of the world and the desired one: it is possible to already have the desired state, but to expect it to vanish if no proper action is executed.
An <a href="https://en.wikipedia.org/wiki/Instability">Unstable state</a>, like an <a href="https://en.wikipedia.org/wiki/Inverted_pendulum">inverted pendulum</a>, is of this kind: we first act to reach a desired state and, when this state is reached, we act in order to maintain it.
In such a situation, the goal does not come from the unsatisfaction of the current state, but from the expectation that the future state will be different from the future state we want to have.
Thus, the goal is not motivated by the difference between the current and the wanted state, but between two expected future states: the one expected if no (good) action is performed, and the one expected the other way around.
Nevertheless, the current state remain important, because we cannot infer the future state from the action alone, we need to know in which context this action is performed.
This is where the current state becomes important: this is the combination of the current state and the (absence of) action which leads to the (expected) future state.
The particular case of comparing the current state to the desired one occurs when one expect the current state to remain stable, in other words it is a shortcut to inferring first the natural future state and then comparing it to the desired state.
In brief, a goal occurs when identifying a difference between two future states: the one we expect to occur naturally from the current state, and the one we want to reach from this same current state.
This goal leads then to perform some actions such that the future state we expect to happen becomes our desired state or come closer to it.
</p>

Dunning, David. “Prediction: The Inside View.” In Social Psychology: Handbook of Basic Principles, edited by Arie W. Kruglanski and E. Tory Higgins, 2nd ed., 69-90. New York: Guilford Press, 2007.
<!-- TODO Can we use it for the notion of goal, such that the expected and wanted futures are predictions occurring with different planned behaviours? -->
- Focus on failures (e.g. what makes a prediction bad/wrong), not success. Properties should be inferred out of it, but more support might be needed.
- Principles of outcome: patterns researchers typically find when they explore the level of accuracy and bias in prediction. <!-- TODO This should be human-independent, because we focus on the outcome, thus prediction properties -->
	- Undue optimism due to overprediction of desirable events <!-- TODO Seems like a human characteristic, where predictions are biased towards more positive or less negative expectations. Maybe it is an average trend, but there is also clearly pessimistic people, so the reverse is also possible. Thus, it makes hard to generalise this bias to machines, because it seems to be more a matter of personality than a matter of measure error. -->
	- Undue optimism due to planning fallacy (time to proceeed usually exceeds expected time) <!-- TODO May be due to lack of information, and lack of awareness of this lack of information. Probably relates to unknown and unknowable details later. -->
	- Overconfidence <!-- TODO This one is not clear, because we can speak about 2 probabilities: the probability to be correct for a specific prediction, which is a matter of information at hand and which can vary for each new prediction (Bayesian approach), and the probability to be correct in general, which is a matter of average success and is independent of personal opinions (frequentist approach). A deeper reading should be done on the cited literature to check that they are not mixed. -->
- Principles of process: psychological processes by which people reach their predictions. <!-- TODO This should be human-dependent, because we focus on the way the outcome is produced, which depends on the "implementation" -->
	- Scenario-building process <!-- TODO Building a scenario is only one way for establishing a prediction. The author states that the likelihood of the prediction then depends on the number of alternative scenarios available, their simplicity, facility of construction, and plausibility. Another way is the mere probability computation, as we may do with neural or Markov networks. It is important to consider several ways to produce predictions, because although the scenario building strategy provides plans which may be executed by the agent, the inability to find such a plan may, because of the high likelihood of the prediction, become a source of goal: try to find out what will occur in order to understand not only whether or not your prediction is correct but also why. -->
	- Incomplete scenario building, abstract without concrete, especially for distant future <!-- TODO In particular, this point highlights that if we consider a high level category, which further splits into more concrete ones, we come with a given idea about the whole category which does not fit the aggregation of the ideas we have about each of the concrete ones. For example, we may have an estimation of the likelihood of homicides in general which does not fit our estimations of the likelihood of specific kinds of homicides put together (Check in: Rottenstreich & Tversky, 1997; Tversky & Koehler, 1994). Planning fallacy can occur due to that. It seems to me, however, that it is a good thing to think more abstractly the distant future, precisely because even more things can happen which would disturb any concrete plan. This abstractness appears to me more as a feature which makes one more adaptable, because it keeps in mind the principal aspects and remain flexible on the details. -->
	- Incomplete scenario building, central outcomes without alternatives <!-- TODO More precisely, we speak here about a bias towards specific aspects, in particular stated aspects, while forgetting to consider other aspects, in paticular opposite of complementary ones. The same way a prestidigitator would focus the attention of his audience on what he wants in order to hide his tricks, asking people whether or not they think someone has a given traits would lead them to search for evidences of that traits while omitting evidences against it. In particular, one may focus on establishing scenarios leading to a successful outcome while forgetting to think about scenarios leading to a failure. However, if we assume that any other scenario would lead to failure, then it can actually be a good way to foster motivation: by establishing a "floor" estimation, one may focus better on what appears to be needed to achieve the goal. At the opposite, looking only at failure scenarios, and seeing that the chances to fail are not that high (potentially because we don't see all of them), one may increase his chances to actually fail because of lack of effort. Motivation would of course not be relevant for a machine, but if we generalise it to an optimisation of resource usage or goal achievement, this kind of bias can be worth it. But in general, one should try to be as exhaustive as possible in order to have a reliable estimation. -->
	- Incomplete scenario building, optimistic without pessimistic, especially for distant future <!-- TODO If it is about a goal to achieve, having more delay means -usually- that it is easier to achieve because one has more time to prepare, find, or execute plans. Thus, it seems logical to be more optimistic about a more distant future goal. In the case of an event on which we don't plan to have any influence, it seems more arguable. -->
	- Incomplete scenario building, focalism <!-- TODO Focalism is about considering aspects clearly relevant, but forgetting about everything else that happen around it although it may have a significant impact too. For example, how a bonus given to everyone seems good despite giving it to everyone is equivalent to not giving it at all. Or how comparing alternative choices may focus on clear differences rather than almost similar features, although the small differences in the latter might have a greater impact than the big differences in the former. -->
	- Incomplete scenario building, strength of evidence without weight <!-- TODO By strength, we mean how the evidence, if reliable, may actually lead to the outcome, while weight means how reliable it is. We could restate it as focusing too much on how the link between cause and consequence is plausible, while neglecting how the cause itself is plausible. For example, having 3 flips of a coin giving head is a strong evidence towards a head bias, but there is just not enough flips (weight) to make such a conclusion reliable. -->
	- Limited utility of scenario building, Unknown and unknowable details <!-- TODO p. 78. Does it relate to planning fallacy above? -->
	- Limited utility of scenario building, Inaccessibility and impact of emotions <!-- TODO -->
- Principles of improvement: ways that people could approach their predictions to ensure greater accuracy. <!-- TODO Is it human-dependent or not? -->
	- Data-based process <!-- TODO -->
	- Cognitive repairs <!-- TODO -->
	- Aggregating predictions <!-- TODO -->

<!-- TODO Read "Social psychology: handbook of basic principles" on Zotero, in particular chapter 21 "The Goal Construct in Social Psychology" -->
<!-- TODO Read "Handbook of self-regulation: research, theory, and applications" on Zotero -->
<!-- TODO Search "A Theory of Goal Setting and Task Performance" -->
<!-- TODO Check "The Cambridge handbook of thinking and reasoning" on Zotero -->

<h3 id="preliminary_formalisation">Formal Concepts to Build on</h3>

<p>
<!-- TODO -->
</p>

<h3 id="absolute_formalisation">Formalisation of Absolute Relevance and Irrelevance</h3>

<p>
<!-- TODO -->
</p>

<h3 id="relative_formalisation">Formalisation of Relative Relevance and Irrelevance</h3>

<p>
<!-- TODO -->
</p>

<h2 id="answer">Answer</h2>

<p>
<!-- TODO -->
</p>

<h2 id="links">Related Questions</h2>

&lt;Links to other questions.&gt;

<h2 id="bibliography">Bibliography</h2>

<ul>
<!--
<li id="Prindle1948">
	Prindle, Lester M.
	<cite>Some Negative Prefixes in English</cite>,
	The Classical Weekly 41, no. 9 : 130,
	<time datetime="1948">1948</time>.
	DOI:<a href="https://dx.doi.org/10.2307/4342404">10.2307/4342404</a>
</li>
<li id="Goguen1984">
	Goguen, Joseph A.
	<cite>Parameterized Programming</cite>,
	IEEE Transactions on Software Engineering SE-10, no. 5, 528–43,
	<time datetime="1984-09">1984-09</time>.
	DOI: <a href="https://dx.doi.org/10.1109/TSE.1984.5010277">10.1109/TSE.1984.5010277</a>
</li>
<li id="MusserStepanov1989">
	Musser, David R., and Alexander A. Stepanov.
	<cite>Generic Programming</cite>,
	Symbolic and Algebraic Computation, edited by P. Gianni, 358:13–25. Berlin, Heidelberg: Springer Berlin Heidelberg,
	<time datetime="1989">1989</time>.
	DOI: <a href="https://dx.doi.org/10.1007/3-540-51084-2_2">10.1007/3-540-51084-2_2</a>
</li>
<li id="Vergne2017">
	Vergne, Matthieu.
	<cite>Artificial Intelligence and Expertise: The Two Faces of the Same Artificial Performance Coin</cite>,
	Workshops at the Thirty-First AAAI Conference on Artificial Intelligence,
	<time datetime="2017">2017</time>.
	URL: <a href="http://www.aaai.org/ocs/index.php/WS/AAAIW17/paper/view/15148">http://www.aaai.org/ocs/index.php/WS/AAAIW17/paper/view/15148</a>
</li>
-->
</ul>

</body>
</html>