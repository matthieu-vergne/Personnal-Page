<!DOCTYPE html>
<html lang="en">
<head>
	<title>Blog Page</title>
	<meta charset="utf-8">
	<link href="../style.css" rel="stylesheet" type="text/css" />
	<script type="text/x-mathjax-config">
		MathJax.Hub.Config({
			TeX: {
				extensions: ["color.js"],
				equationNumbers: { autoNumber: "AMS" },
			}
		});
	</script>
	<script language="JavaScript" type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
	<script src="https://cdn.rawgit.com/google/code-prettify/master/loader/run_prettify.js"></script>
</head>
<body id="blog">
<h1>How to formalise a goal?</h1>

<h2 id="context">Context</h2>

<p>
<!-- TODO -->
</p>

<h2 id="question">Question</h2>

<p>
<!-- TODO -->
</p>

<h2 id="method">Method</h2>

<p>
<!-- TODO -->
</p>

<h3 id="dictionary_definitions">Dictionary Definitions</h3>

<p>
<!-- TODO -->
We ignore the definitions related to sports in particular, like the goal in soccer or in a race.
- <q>Goal</q> from <a href="http://dictionary.cambridge.org/dictionary/english/goal">Cambridge Dictionaries</a>:
	- <q>an aim or purpose</q>, in other words a result that one intends to reach or the reason why one does something.
- <q>Goal</q> from <a href="https://en.oxforddictionaries.com/definition/goal">Oxford Dictionaries</a>:
	- <q>an aim or desired result</q>, concepts that the dictionary again relates to the notion of purpose (a reason why), intention, and desired outcome.
	- <q>the object of a person's ambition or effort</q>, which again relates to the desire of someone to achieve something.
- <q>Goal</q> from <a href="https://www.merriam-webster.com/dictionary/goal">Merriam-Webster</a>:
	- <q>the end toward which effort is directed</q>, as a synonym of aim, i.e. a clearly directed intent or purpose.
</p>

<h3 id="formalisation_preparation">Informal Summary Before Proper Formalisation</h3>

<p>
All these definitions link as synonyms the notions of goal, aim, and purpose, but two perspectives can be highlighted: the <em>future result</em> that one desires to produce and the <em>current reason</em> which motivates the act.
The future result put an emphasis on the future, such that we act in order to change (or maintain) the state of the world progressively towards a state that we deem as valuable.
Nervertheless, the future result does not exist at the current time (it might be already the case, but we want it to be the case in the future too), which means that we can only speak about an <em>expected</em> result, such that the action we plan to execute should, to the best of our knowledge, leads this expected result to become (or remain) true.
This is where the current reason is established: one acts based on the incentives it has at the moment of the action, and the reason why one acts can be because this action is &mdash;currently&mdash; expected to lead to a wanted future result.
If we remain loose on the interpretation of the term, other reasons could be considered, like daily routine: although thinking about it may lead to remember the future state we expect to reach through this ation, the actual incentive leading to act is the habit.
This example, and a more broader notion of <em>cause</em>, is however irrelevant in our case, because we loose the intentional aspect that goal, aim, and purpose have been defined with.
If we want to keep this intention then we may speak about trials or attempts, but again these actions can be done in order to reach a wanted future, possibly less specific, like find an answer to a question rather than proove that a particular answer is the right one, but still a wanted future.
We may speak about actions where we don't know what could be the future result of an action, like a random trial, but it seems hard to explain such an action without an automatism or an intention to reach a wanted future through evolutions we think to be probable.
In short, the main interpretation we reach when sepaking about a goal is a desired, future state of the world.<!-- TODO Cite papers about that, check RE -->
</p>

<p>
One should however not fall in the shortcut of considering a goal as a delta between the current state of the world and the desired one: it is possible to already have the desired state, but to expect it to vanish if no proper action is executed.
An <a href="https://en.wikipedia.org/wiki/Instability">Unstable state</a>, like an <a href="https://en.wikipedia.org/wiki/Inverted_pendulum">inverted pendulum</a>, is of this kind: we first act to reach a desired state and, when this state is reached, we act in order to maintain it.
In such a situation, the goal does not come from the unsatisfaction of the current state, but from the expectation that the future state will be different from the future state we want to have.
Thus, the goal is not motivated by the difference between the current and the wanted state, but between two expected future states: the one expected if no (good) action is performed, and the one expected the other way around.
Nevertheless, the current state remain important, because we cannot infer the future state from the action alone, we need to know in which context this action is performed.
This is where the current state becomes important: this is the combination of the current state and the (absence of) action which leads to the (expected) future state.
The particular case of comparing the current state to the desired one occurs when one expect the current state to remain stable, in other words it is a shortcut to inferring first the natural future state and then comparing it to the desired state.
In brief, a goal occurs when identifying a difference between two future states: the one we expect to occur naturally from the current state, and the one we want to reach from this same current state.
This goal leads then to perform some actions such that the future state we expect to happen becomes our desired state or come closer to it.
</p>

<!-- TODO To extract in dedicated posts -->

Dunning, David. “Prediction: The Inside View.” In Social Psychology: Handbook of Basic Principles, edited by Arie W. Kruglanski and E. Tory Higgins, 2nd ed., 69-90. New York: Guilford Press, 2007.
<!-- TODO Can we use it for the notion of goal, such that the expected and wanted futures are predictions occurring with different planned behaviours? -->
- Focus on failures (e.g. what makes a prediction bad/wrong), not success. Properties should be inferred out of it, but more support might be needed.
- Principles of outcome: patterns researchers typically find when they explore the level of accuracy and bias in prediction. <!-- TODO This should be human-independent, because we focus on the outcome, thus prediction properties -->
	- Undue optimism due to overprediction of desirable events Seems like a human characteristic, where predictions are biased towards more positive or less negative expectations. Maybe it is an average trend, but there is also clearly pessimistic people, so the reverse is also possible. Thus, it makes hard to generalise this bias to machines, because it seems to be more a matter of personality than a matter of measure error.
	- Undue optimism due to planning fallacy (time to proceeed usually exceeds expected time): May be due to lack of information, and lack of awareness of this lack of information. <!-- TODO Probably relates to unknown and unknowable details later. -->
	- Undue pessimism: Still few data on that matter, but it seems we may build the same kind of analysis than for undue optimism.
	- Overconfidence: This one is not clear, because we can speak about 2 probabilities: the probability to be correct for a specific prediction, which is a matter of information at hand and which can vary for each new prediction (Bayesian approach), and the probability to be correct in general, which is a matter of average success and is independent of personal opinions (frequentist approach). A deeper reading should be done on the cited literature to check that they are not mixed.
	- Underconfidence: It seems we may build the same kind of analysis than for overconfidence, but we also observe this effect for easy tasks, with some explaining that it can be due to rare occurrences of doing it wrong, thus one would feel more normal than overconfident. Maybe we could relate it to the Dunning-Kruger effect: novices are more confident than they should, while experts are less confident than they should (although this effect is about placing oneself in regard of the others, not evaluating oneself alone). Easy tasks making anyone an "expert" for the task, we may see only the underconfidence end.
- Principles of process: psychological processes by which people reach their predictions. <!-- TODO This should be human-dependent, because we focus on the way the outcome is produced, which depends on the "implementation" -->
	- Scenario-building process: Building a scenario is only one way for establishing a prediction. The author states that the likelihood of the prediction then depends on the number of alternative scenarios available, their simplicity, facility of construction, and plausibility. Another way is the mere probability computation, as we may do with neural or Markov networks. It is important to consider several ways to produce predictions, because although the scenario building strategy provides plans which may be executed by the agent, the inability to find such a plan may, because of the high likelihood of the prediction, become a source of goal: try to find out what will occur in order to understand not only whether or not your prediction is correct but also why.
	- Incomplete scenario building, abstract without concrete, especially for distant future: In particular, this point highlights that if we consider a high level category, which further splits into more concrete ones, we come with a given idea about the whole category which does not fit the aggregation of the ideas we have about each of the concrete ones. For example, we may have an estimation of the likelihood of homicides in general which does not fit our estimations of the likelihood of specific kinds of homicides put together (Check in: Rottenstreich & Tversky, 1997; Tversky & Koehler, 1994). Planning fallacy can occur due to that. It seems to me, however, that it is a good thing to think more abstractly the distant future, precisely because even more things can happen which would disturb any concrete plan. This abstractness appears to me more as a feature which makes one more adaptable, because it keeps in mind the principal aspects and remain flexible on the details.
	- Incomplete scenario building, central outcomes without alternatives: More precisely, we speak here about a bias towards specific aspects, in particular stated aspects, while forgetting to consider other aspects, in paticular opposite of complementary ones. The same way a prestidigitator would focus the attention of his audience on what he wants in order to hide his tricks, asking people whether or not they think someone has a given traits would lead them to search for evidences of that traits while omitting evidences against it. In particular, one may focus on establishing scenarios leading to a successful outcome while forgetting to think about scenarios leading to a failure. However, if we assume that any other scenario would lead to failure, then it can actually be a good way to foster motivation: by establishing a "floor" estimation, one may focus better on what appears to be needed to achieve the goal. At the opposite, looking only at failure scenarios, and seeing that the chances to fail are not that high (potentially because we don't see all of them), one may increase his chances to actually fail because of lack of effort. Motivation would of course not be relevant for a machine, but if we generalise it to an optimisation of resource usage or goal achievement, this kind of bias can be worth it. But in general, one should try to be as exhaustive as possible in order to have a reliable estimation.
	- Incomplete scenario building, optimistic without pessimistic, especially for distant future: If it is about a goal to achieve, having more delay means -usually- that it is easier to achieve because one has more time to prepare, find, or execute plans. Thus, it seems logical to be more optimistic about a more distant future goal. In the case of an event on which we don't plan to have any influence, it seems more arguable.
	- Incomplete scenario building, focalism: Focalism is about considering aspects clearly relevant, but forgetting about everything else that happen around it although it may have a significant impact too. For example, how a bonus given to everyone seems good despite giving it to everyone is equivalent to not giving it at all. Or how comparing alternative choices may focus on clear differences rather than almost similar features, although the small differences in the latter might have a greater impact than the big differences in the former.
	- Incomplete scenario building, strength of evidence without weight: By strength, we mean how the evidence, if reliable, may actually lead to the outcome, while weight means how reliable it is. We could restate it as focusing too much on how the link between cause and consequence is plausible, while neglecting how the cause itself is plausible. For example, having 3 flips of a coin giving head is a strong evidence towards a head bias, but there is just not enough flips (weight) to make such a conclusion reliable.
	- Limited utility of scenario building, Unknown and unknowable details: Some actions might be supported by factors which can only be known (practically speaking) once we are close to the time it occurs. For exmple, the will of someone to help someone else depends not only on the persons involved, which might be known in advance, but also on their mood at that time, on how many people are available to help too, etc. Surely, predictions which significantly depend on factors which cannot be known should be considered as unknown. Not even random variables because we do not have the information for evaluating reliably their probabilities. And plans depending on them should then consider every alternatives rather than the most likely cases, simply because we cannot identify which are the most likely. To reduce the effort due to exhaustiveness, one should consider few categories which cover the whole spectrum of possibilities, categories which should be designed based on their ability to lead to similar inferrences. Thus, the effort is first of all a matter of finding a good modelling rather than spending time evaluating each case, which leads to theory building.<!-- TODO Does it relate to planning fallacy above? -->
	- Limited utility of scenario building, Inaccessibility and impact of emotions: In particular, one might neglect the impact of emotions on actions, but also the impact of events on emotions. This is a special case of unknown details, but this one is about oneself, thus we might expect it to be known. This issue then may be related to a lack of knowledge about oneself. A solution to that might be again to consider that we don't know, or to learn about or shape it in such a way that it became known. However, this is also true in general: whether we consider it as unknown, whether we build a theory about it based on evidences, whether we influence it to fit a theory we want to use.
- Principles of improvement: ways that people could approach their predictions to ensure greater accuracy. <!-- TODO Is it human-dependent or not? -->
	- Data-based process: Rather than building a fictional scenario, one should try to build on similar past experiences (from oneself or from others), thus producing a data-driven estimation. Preferably, one may count on previous experiences which cover at best the whole process, rather than small pieces of it. The point is to look for this data if we don't have it yet, rather than make a scenario based on personal assumptions.
	- Cognitive repairs: Rather than replacing a fictional scenario by a purely data-based process, if systematic errors are known, one can apply systematic fixes. For example, knowing that one is often late by about 20% to the estimated plans, one can artificially add 20% more time to these plans (or even more for margins) to increase the accuracy of the plans.
	- Aggregating predictions: Instead of considering the estimation of one individual, aggregate the estimations of several (different) individuals. Aggregations erase individual differences and usually provide a more reliable estimate, as long as most individuals don't make the same mistakes or are not fundamentally wrong. An important point is that we aggregate independent estimates, we do not build a consensus by letting the individuals exchange estimations (consensus has other drawbacks). Estimations are built separately and then aggregated.<!-- TODO Look for works on that aspect in AI and others, like boosting which aggregates weak learners. -->
- Rather than aiming for accurate predictions, some people might make strategic predictions: <q>defensive pessimists</q> tend to worsen their predictions before to go through them (potentially to enjoy better the actual outcomes), while <q>strategic optimists</q> tend to make optimistic predictions while paying less attention to the actual outcomes (potentially to improve their motivation, and thus their ability to perform well). More generally, it has been observed that predictions can be made to satisfy various goals, not only accuracy, in particular by comparing predictions before taking decisions (try to be correct) and after (try to increase chances of success).
-  <q>the relations among individual differences, goals, optimism, and confidence have yet to be exhaustively explored, and so remains a topic of tremendous potential for research.</q>

Roese, Neal J., and Jeffrey W. Sherman. “Expectancy.” In Social Psychology: Handbook of Basic Principles, edited by Arie W. Kruglanski and E. Tory Higgins, 2nd ed., 91–115. New York: Guilford Press, 2007.
<!-- TODO Can we use it for the notion of goal? What is the difference with prediction? -->
<!-- TODO Read the chapter of the first edition. -->
- Expectancies = <q>beliefs about a future state of affairs, subjective estimates of the likelihood of future events ranging from merely possible to virtually certain.</q> (Olson, Roese, & Zanna, 1996)
- Function:
	- Behavior regulation: <q>expectancy is where past and future meet to drive present behavior</q>, it draws on information gleaned from previous experience to act effectively in the world in order to reach an expected future state. Several aspects has been investigated, including accuracy, control, improvement, affiliation, and affect regulation (e.g., Fiske, 2003; Sanna, 2000; Sedikides & Strube, 1997), but the most basic seems to be behaviour control, for survival as well as other (and more modern) goals. Complex goals may need a system of expectancies, like a superordinate goal (the main purpose), plans (subordinate goals required to achieve the superordinate goal), semantic expectancies (implicit background assumptions), and episodic expectancies (past similar experiences).<!-- TODO Check papers: "Regulatory feedback loops are a defining feature of goals (Austin & Vancouver, 1996), and indeed they pervade an expectancy system simultaneously and at multiple levels." / "the same conceptual operation, widely known as a TOTE unit (see Miller, Galanter, & Pribram, 1960), occurs over longer time periods and for larger goals." --> A current-state similar to the expected one seems normal and requires no change in behavior, while a state that is suddenly dissimilar seems abnormal and does require change in behavior.<!-- TODO Speaking only about current state seems to limited, though. One is to expect a state, another is to predict it, prediction which might just be a mere observation if we speak about a state close enough to present time. The whole point is to notice the difference between the expectancy and the prediction/observation. --> In a normal situation, expectancies provide background assumptions, while in abnormal situations they bring a sense of how it <q>ought to have been</q>. Such a behavior control imposes a continuous comparison between current and expected state, as may go in parallel the continuous comparison between current and recent past state. <q>Processing fluency</q> characterises the degree of similarity induced from these comparisons<!-- TODO Check papers: Benjamin & Bjork, 1996; Jacoby & Dallas, 1981; Johnston & Hawley, 1994; Whittlesea & Williams, 2001 -->, while <q>processing disfluency</q> is about their differences and act as an alarm.<!-- TODO Check papers: Lieberman, Gaunt, Gilbert, & Trope, 2002 -->
	- Efficiency: expectancies must deliver accurate information in an efficient way.<!-- TODO It might be impotant for fast, local decisions, but for more global decisions which has some inertia, it seems less important, thus not fundamental. -->
- Determinants and parameters:
	- Likelihood: How likely or probable is the expectancy. A moderate likelihood, like 50% chance to guess whether a coin will give head or tail, has small influence on decisions due to the inability to discriminate what will happen, while a strong likelihood (low or high) makes it a potential relevant criteria for decision making.
	- Confidence: Orthogonal to likelihood, confidence is about reliability, like a fair coin would lead to a <em>confident</em> belief of having a <em>moderate likelihood</em> (50% chance) to guess whether the coin will give a head or tail. While likelihood is inferreed from the information at hand, confidence judges the reliability of this information.<!-- TODO We could probably call it the likelihood of the information to be correct. But then we can go further in recursion: what is the likelihood to judge correctly the reliability of this information? And what about the likelihood to judge correctly whether this judgement of reliability is correct? And so on. The recursion may stop if we find a loop, like the likelihood of a given level is equivalent to the likelihood of the next level. The point is that likelihood "comes from" a piece of information, while confidence "is about" this piece, thus the confidence we have about an information A can be described as a likelihood based on information B. Check "Confidence, likelihood, probability: statistical inference with confidence distributions" in Zotero to compare with statistical interpretations. -->
	- Abstractness: Abstract expectancies (exemplified from semantic memory) are generalised from more concrete, specific ones (instantiated from episodic memory), thus covering multiple events, people, and contexts. In humans, semantic (abstract) expectancies seem to occur more rapidly and by consuming less resources than their episodic (concrete) counterparts, thus being more efficient. However, episodic expectancies bring more details, which support further analysis or remind exceptions to the general rules.<!-- TODO Some have argued that the main evolutionary purpose of episodic memory is to store instances that violate general expectancies about the world (e.g., McClelland et al., 1995; Schank, 1982; Sherry & Schacter, 1987). It might be a performant way to use similar constructs, although exceptions might occur also in more abstract levels. --> Abstract expectancies are also more used for future events, where it is hard to motivate specific details, than for events close to present time, where a lot of available details can be used for prediction.
	- Accessibility: An accessible expectancy is brought to conscious attention with ease, e.g. because it is recent or frequent, thus making it easier to consider. It does not necessarily depends on the expectancy itself: if the situation is incompatible with the expectancy, this expectancy may strike through the mind and lead to a sense-making process to explain the discrepancy. At the opposite, if the situation is compatible, we may barely think about it because it is just a normal situation.
	- Explicitness: Explicit expectancies are stated in some way, while implicit expectancies occur more as background assumptions. Both explicit and implicit expectancies occur, and while some human behaviours appear to be compatible with their explicit expectancies, other are not, and thus seem to bring implicit expectancies in conflict with the explicit ones.
	- Beside these parameters, a different representation can be used, like the typological approach that defines discrete subtypes of expectancies (Miceli & Castelfranchi, 2002).
- Behavioral consequences:
	- General guides: semantic expectancies drive global behaviours through the underlying assumptions they provide. They allow to identify a <q>set of broadly generic roadmaps</q> to follow.
	- Success facilitator: To some extents, expecting future success favors future success by increasing motivation and planning. If the first one is about giving more energy to perform, the second is about providing a more reliable base to perform correctly. It can be seen as favoring both success-driven behaviours (focus on wanted outcomes) as well as failure-avoiding ones (focus on unwanted outcomes), although the former seems more prevalent.
	- Commitment through optimism: Before to commit to any action, people appear to be rather unbiased, while once committed, they tend to be more optimistic, leading to the effects described in the previous point.
	- Resilience through pessimism: People also anticipate various problems and face a bias by expecting worse outcomes to bypass the potential of future regret. It can be particularly effective when there is many obstacles.
	- Self-fulfilling: Rather than success, expectancies can favor prediction fulfilling in general, even failure. By making explicit a prediction, one may think about a priori explanations, which leads to a kind of planning, which then naturally pushes towards remaining consistent with the prediction. Consequently, the behaviour may be different between people making a priori predictions (on themselves or on something they may interact with) and people who do not, leading self-fulfilling prophecies or placebo effects. However, such an effect can be reduced through accuracy motivation and awareness of the expectancy (awareness of the perceiver or the target), in particular for unwanted expectancies.
- Cognitive consequences: <q>At a basic level, expectancies guide processing in a manner that is self-perpetuating</q>, revision might be done, but generally speaking it is conservative with some specialised processes to spot inaccuracies, encode unexpected events, and integrate them. A cognitive system that is either too flexible or too stable seems indeed evolutionary disadvantaged<!-- TODO See Johnston & Hawley, 1994; Sherry & Schacter, 1987; Tulving, Markowitsch, Kapur, Habib, & Houle, 1994 -->. Expectancies <q>help to maximize the ratio of useful information gained for effort expended</q><!-- TODO See Sherman, 2001; Sherman, Lee, Bessenoff, & Frost, 1998 -->.
	- Expectancy Confirmation and Disconfirmation: Confirmation happens when there is small to no difference between what is observed and what is expected, leading to a general sense of normal. Such a situation leads to go ahead with the current plan, with no need for corrective actions. Disconfirmation, at the opposite, occurs from a significant difference between expected and observed signals, leading to a heightened vigilance with, possibly, corrective actions, whether they are behavioural (wrong plan leading to new actions) or conceptual (wrong expectancy leading to conceptual repair). <em>Vigilance</em>, <em>problem-solving</em>, and <em>belief repair</em> are the three main activities induced by disconfirmed expectancies. In particular, one seeks for information in order to test one's expectancies, although humans seem to search more confirmation evidences than disconfirmation ones<!-- TODO Check chapter of the first edition (1996) for details -->. Theories have converged on the idea that a continuous pattern matching is performed between sensory inputs and semantic memory, and while a smooth alignment provides a feeling of fluency and comfort (processing fluency), mismatches generates surprise (processing disfluency). Such mismatches grab the <em>attention</em> of the actor, for example a long gaze duration, in particular when the actor lacks processing resources, leading to an attention focused even more on mismatches and even less on matches. Individual differences may also give priority to some mismatches over others. Additionally, matches leading to poor attention, few perceptual details are encoded despite the good understanding (i.e. rich conceptual encoding), at the opposite of mismatches which lead to further attention, and thus a better encoding of details despite the low understanding (i.e. poor conceptual encoding). At the interpretational level, expectancies can act as heuristics, for quick judgement, and as view points, by supporting a given interpretation.
	- Coping with Disconfirmation: Disconfirmation leads to the need to make sense of the discrepancy by bridging the gap between prior understanding and current experience. This bridging can be done in several ways: <em>causal attribution</em> (which has the greatest amount of evidences) aims at guessing the cause of the event, <em>counterfactual thinking</em> elaborates on what would have happened if the cause was different, and <em>hindsight bias</em> supports the confidence that such an event was to be expected. The final result can be of different level: <em>ignoring</em> when no (enough) information is available for processing, <em>tagging</em> if the event is still deemed worth remembering for future processing (with the attention leading to a great degree of encoding), especially as exceptions to the general expectancy, <em>bridging</em> by adding new inferential material while preserving the consistency of the current conceptual model, one of them being to consider the new case as an exception to the rule, and <em>revising</em> which carefully updating the conceptual model to make it fit the evidence. The latter covers both conversion (mindshifting) and bookkeeping (expertise development). The level of the result depends on the magnitude of the discrepancy (ignore low magnitude, tag or bridge high magnitude, revise moderate magnitude) and the complexity of the conceptual model. This latter also reflect the level of expertise of the actor: low expertise (i.e. simple model) faces more lacks than proper discrepancies, leading more often to revision through addition, while a moderate expertise allows to spot proper discrepancies and revise through fixes, and an expert level -thus prone to be correct- would rarely spot deep discrepancies and more often rely on bridging.
	- Representation: Expected events, due to the lack of attention they face, are mainly stored in terms of the semantic expectancies they are linked to, while unexpected events tend to be represented in terms of detailed, episodic memories.
	- Memory: Expected events are not memorised in the same way than unexpected ones because of the various reasons already exposed before. Free recall (retrieve without cue) and recognition (tell whether a presented item was seen) seem both more efficient on unexpected events. More details, bridges with other pieces of knowledge, and greater time spent on them are some explanations. The need for congruence might also lead to biased responses, particularly for responses which are to be expected, because they build on less detailed and more abstract encodings. These biases may lead to false memories and testimonies build on congruence rather than factual evidence. As expectancies become more clearer, incongruent events become more surprising while congruent events are more taken for granted<!-- With an increase in expertise leading to less disconfirmation, the general tendency is towards less surprises. --> (which increases the previous effects).
- Affective consequences: <q>affect constitutes an informational signal intrinsic to behavior regulation</q>, affect may show for example whether or not progress goes smoothly.
	- Behavior-Oriented Affective Consequences: Disconfirmation leads by default, in an immediate manner, to negative affect, like regret and disappointment, which can push for greater effort in problem solving tasks. But expectancies also frame the perspective, such that disconfirming an expected failure leads to positive affects. Moreover, the resulting affect is strengthen if the result is unexpected. For example, a failure will lead to greater disappointment if success was expected, or a success will lead to further joy if failure was expected. The usual explanation of this phenomenon is the conceptual contrast between the expectancy and the observation: a success should lead to positive outcome in average, but an individual expecting failure should feel greater joy because of the higher contrast between the expected failure and observed success. Some recent evidences may suggest other interpretations, though. Applied consciously, a strategy used by some people is to build lower expectancies to push forwards one's performance and get more positive affects from the actual result.
	- Optimism and Affect Regulation: People are, on average, optimistic (and potentially unrealistic, like with the planning fallacy), although there is variations between individuals and cultures. Such optimism is usually explained through the positive affect it brings (i.e. it feels good on several levels, so people tend to do it more), through the emphasis of self-relevant information (i.e. discard seemingly irrelevant information which may actually have an impact), or other explanations. People also face an <em>impact bias</em>, the <q>tendency to exaggerate the emotional impact of future events</q>, which is applicable to both positive and negative affects. Although it might seem in contradiction with the average optimism, both actually build on different questions: given a future situation (good or bad), people tend to exaggerate its emotionnal impact, but if we ask people to predict the future situation by themselves, they tend to predict more optimitic ones.
	- Broader Affective Consequences: Past research has linked attitudes to the intersection of expectancy and value, but a more recent controversy tend to argue that past findings on that matter may be ambiguous due to statistically inappropriate techniques. It has also been observed that aesthetic appreciation reflects moderate surprise: small changes are boring (not enough discrepancy to notice it), large ones are bizarre (requires too much effort to understand it), restricting pleasant surprises in the moderate level (enough discrepancy to notice the novelty, but still close enough to foster simple explanations able to highlight the novel part)<!-- TODO A potential explanation to the rejection of papers which are too much incremental or novel. -->. The contrast effect from low fluency at first to high fluency at last may be the trigger towards the pleasant feeling<!-- TODO Although it would reduce the notion of aesthetics to a notion of self-congratulation: one is expert enough to see the difference, and further expert enough to explain it. -->. Humor might come through the same process, with a quick transition from incongruity to congruity leading to a good laugh, such that further the shift, greater the laugh. The negative counterpart of depression, at the opposite, builds on hopeless expectancies, in particular for future and important events.

Fishbach, Ayelet, and Melissa J. Fergusson. “The Goal Construct in Social Psychology.” In Social Psychology: Handbook of Basic Principles, edited by Arie W. Kruglanski and E. Tory Higgins, 2nd ed. New York: Guilford Press, 2007.
<!-- TODO p. 490 -->

<!-- TODO Read "Handbook of self-regulation: research, theory, and applications" on Zotero -->
<!-- TODO Search "A Theory of Goal Setting and Task Performance" -->
<!-- TODO Check "The Cambridge handbook of thinking and reasoning" on Zotero -->

<h3 id="preliminary_formalisation">Formal Concepts to Build on</h3>

<p>
<!-- TODO -->
</p>

<h3 id="absolute_formalisation">Formalisation of Absolute Relevance and Irrelevance</h3>

<p>
<!-- TODO -->
</p>

<h3 id="relative_formalisation">Formalisation of Relative Relevance and Irrelevance</h3>

<p>
<!-- TODO -->
</p>

<h2 id="answer">Answer</h2>

<p>
<!-- TODO -->
</p>

<h2 id="links">Related Questions</h2>

&lt;Links to other questions.&gt;

<h2 id="bibliography">Bibliography</h2>

<ul>
<!--
<li id="Prindle1948">
	Prindle, Lester M.
	<cite>Some Negative Prefixes in English</cite>,
	The Classical Weekly 41, no. 9 : 130,
	<time datetime="1948">1948</time>.
	DOI:<a href="https://dx.doi.org/10.2307/4342404">10.2307/4342404</a>
</li>
<li id="Goguen1984">
	Goguen, Joseph A.
	<cite>Parameterized Programming</cite>,
	IEEE Transactions on Software Engineering SE-10, no. 5, 528–43,
	<time datetime="1984-09">1984-09</time>.
	DOI: <a href="https://dx.doi.org/10.1109/TSE.1984.5010277">10.1109/TSE.1984.5010277</a>
</li>
<li id="MusserStepanov1989">
	Musser, David R., and Alexander A. Stepanov.
	<cite>Generic Programming</cite>,
	Symbolic and Algebraic Computation, edited by P. Gianni, 358:13–25. Berlin, Heidelberg: Springer Berlin Heidelberg,
	<time datetime="1989">1989</time>.
	DOI: <a href="https://dx.doi.org/10.1007/3-540-51084-2_2">10.1007/3-540-51084-2_2</a>
</li>
<li id="Vergne2017">
	Vergne, Matthieu.
	<cite>Artificial Intelligence and Expertise: The Two Faces of the Same Artificial Performance Coin</cite>,
	Workshops at the Thirty-First AAAI Conference on Artificial Intelligence,
	<time datetime="2017">2017</time>.
	URL: <a href="http://www.aaai.org/ocs/index.php/WS/AAAIW17/paper/view/15148">http://www.aaai.org/ocs/index.php/WS/AAAIW17/paper/view/15148</a>
</li>
-->
</ul>

</body>
</html>