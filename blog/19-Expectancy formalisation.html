<!DOCTYPE html>
<html lang="en">
<head>
	<title>Blog Page</title>
	<meta charset="utf-8">
	<link href="../style.css" rel="stylesheet" type="text/css" />
	<script type="text/x-mathjax-config">
		MathJax.Hub.Config({
			TeX: {
				extensions: ["color.js"],
				equationNumbers: { autoNumber: "AMS" },
			}
		});
	</script>
	<script language="JavaScript" type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
	<script src="https://cdn.rawgit.com/google/code-prettify/master/loader/run_prettify.js"></script>
</head>
<body id="blog">
<h1>How to formalise expectancy?</h1>

<h2 id="context">Context</h2>

<p>
<!-- TODO
Goal: define expectancy such that expectancy - observation = error, which is the trigger for conceptual revision (i.e. learning)
-->
</p>

<h2 id="question">Question</h2>

<p>
<!-- TODO -->
</p>

<h2 id="method">Method</h2>

<p>
<!-- TODO -->
</p>

<h3 id="dictionary_definitions">Dictionary Definitions</h3>

<p>
<!-- TODO -->
</p>

<h3 id="scientific_definitions">Scientific Definitions</h3>

<p>
<a href="#OlsonRoeseZanna1996">Olson et al.</a> mention that at least two kinds of expectancies have been considered in the literature of social psychology<!-- TODO At that time, to be updated -->.
One is <em>normative expectancies</em>, which are about what <em>should</em> happen in the future<!-- TODO example -->.
Another is <em>probabilistic expectancies</em>, which are about what <em>might</em> happen in the future and, thus, will be our main focus here.
</p>

<p>
<a href="#OlsonRoeseZanna1996">Olson et al.</a>:
<q>
Expectancies are beliefs about a future state of affairs. They are subjective probabilities linking the future with an outcome at some level of probability ranging from merely possible to virtually certain.
</q>
Expectancy is a <em>belief</em> about an <em>outcome</em> assumed to occur <em>in the future</em> with a given <em>probability</em>.
Expectancy is future-focused: one does not expect about past outcomes.
Regarding outcomes we believe to have occurred in the past, we may see them as expectancies about future information to come, like: I believe that Jane went to the cinema yesterday (past event, not expectancy), so I expect her to confirm/speak about it when she comes back tomorrow (future event, expectancy).
<!-- TODO Is it relevant to do the distinction between beliefs about past and future events? -->
<q>The central mechanism is motivation in its simplest form: the basic tendency to approach pleasant things and to avoid noxious things.</q>
Expectancy acts as a trigger.
<q>The relation of expectancies to performance received initial attention in the context of <q>level of aspiration,</q> which refers to desired levels of future performance (Lewin, Dembo, Festinger, &amp; Sears, 1944).</q>
Not only expectancies can be used to evaluate errors when performing to identify improvements to do, but it can also be used to evaluate error about performance level itself for regulating efforts, in particular to act as a trigger to improve (or stop if we expect higher performance to be useless).
<!-- TODO Interesting sources to consider may be (Rotter, 1954) about social learning theory, and (Tolman, 1932) expectancy model of reinforcement learning. (Edwards, 1954) can be of interest too. -->
<!-- TODO Related to expectancy, although different because more goal-focused, is the notion of set used by (Jones and Thibaut, 1958) and (Zajonc, 1960) -->
Expectancy can be <em>explicit</em>, the outcome being consciously expected and the expectancy potentially stated, or <em>implicit</em>, generating the same state of surprise when contradicted by observation but without preparation.
<!-- TODO -->
<q>All expectancies are derived from beliefs (i.e., our knowledge/schemas about the world)</q> and the authors provide some details about the types and sources of these beliefs.
In particular, beliefs may come from direct experience, be taught or shared by other people, or be inferred from other beliefs.
The authors discuss four properties of expectancies: its certainty, its accessibility, its explicitness, and its importance.
<em>Certainty</em> is <q>the subjective level of probability associated with the anticipated outcome/event</q>, from very uncertain to absolutely certain. We may also speak about confidence, which is <q>the range of possible likelihoods</q>, from large ranges for uncertain expectancies (no idea, it can be anything) to narrow ones for certain expectancies (the coin will for sure fall on head with 50% probability). Certainty is determined based on whether the agent directly experiences it, whether other agents reach a consensus about it, whether it has been (dis)confirmed in the past, and also depending on its accessibility (described below).
<em>Accessibility</em> is <q>the likelihood that the expectancy will be activated</q> and <q>predicts the likelihood that it will be used to interpret reality (Bruner, 1957; see Higgins, Chapter 5, this volume).</q> An expectancy which comes to mind more frequently or rapidly is more accessible. Accessibility is determined by the frequency of its activators, their recency, their importance (described below), and how they are disconfirmed (the consequent surprise leading to making the agent aware of the disconfirmed expectancy it holds).
<em>Explicitness</em> is whether an expectancy is generated consciously (explicit) or inconsciously (implicit), <q>see Ditto &amp; Hilton's discussion of the characteristics of expectancies, 1990, p. 99</q>. Implicit expectancies have effects that can be considered as <q>examples of "automatic" processing (see Bargh, 1984; Uleman &amp; Bargh, 1989).</q> Explicitness can be due to the requirement of the expectancy for planning an event, to an explicit question about the expectancy, to the importance of the expectancy, and to their propensity to be disconfirmed.
<em>Importance</em> is the <q>motivational significance</q> of the expectancy, and is determined by the relevance to important needs and relation with other (important or numerous) expectancies.
Expectancies have many consequences, whether they are cognitive, affective, behavioral, or physiological. For the sake of our study, we will mainly focus on the cognitivie and behavioral ones, since affective and physiological consequences can be irrelevant for a machine.
<strong>Cognitive consequences</strong>
On the cognitive aspect, <q>expectancies direct attention and thus influence what information gets encoded (see Higgins &amp; Bargh, 1987).</q> On one side, people <q>see what they expect to see</q> (see Rothbart, Evans, &amp; Fulero, 1979), but on the other <q>information that is inconsistent with expectancies also gets noticed (e.g., Hastie &amp; Kumar, 1979).</q> In other words, expectancies allow to spot quickly the pieces of information to revise while spending less time on already known ones. <q>Both consistent and inconsistent information will receive more processing than irrelevant information (Hashtroudi, Mutter, Cole, &amp; Green, 1984; Stern, Marrs, Millar, &amp; Cole, 1984).</q> This is an important aspect for an intelligent machine, since it allows to spot the required improvements to increase performance while ensuring that increasing experience comes with increasing efficiency.
Going further on the encoding part, <q>expectancies guide the interpretation of information, especially objectively ambiguous information. Specifically, information is likely to be interpreted in line with expectancies (i.e., as supporting, or confirming) rather than as opposing (disconfirming) expectancies.</q> This is particularly important since be the source of biases: a particular attention should be put in ensuring that machines leverage such effects by calculating the unicity of an interpretation. If other interpretations are compatible with the observations, then each of them should be considered as a potentially biased one, and further information should be seek to reduce the set of compatible interpretations.
Attributions are causal explanations for events or outcomes, and expectancies have noticeable effects on this domain: <q>unexpected events trigger attributional processing (e.g., Crocker, Hannah, &amp; Weber, 1983; Hastie, 1984; Pyszczynski &amp; Greenberg, 1981; Wong &amp; Weiner, 1981)</q>, with disconfirmation leading to causal search, often leading to attribution to <q>external and unstable causes (Miller &amp; Ross, 1975; Weiner, 1986)</q> like luck or mood. Attributions also influence expectancies: <q>if success is attributed internally, future success will be expected (Weiner, 1986)</q>.
Counterfactual thinking, the capacity to imagine what might have been if the past was different, has a spread influence: affect, self and social judgement, behavior <q>(for a review, see Miller, Turnbull, &amp; McFarland, 1990; Roese &amp; Olson, 1995)</q> and expectancies have a <q>central impact</q> on at least two levels <q>(Kahneman &amp; Miller, 1986)</q>. Like attributions, disconfirmations <q>trigger greater counterfactual processing</q>. Expectancies also <q>shape the semantic content of counterfactual thoughts</q>: counterfactuals seems to be built by recapitulating expectancies, such as to preserve them. Counterfactual thinking also influences expectancies, such that (un)wanted counterfactuals may lead to behaviours -and their corresponding expectancies- revisions.
Memory is more efficient in encoding relevant, and in particular inconsistent, information due to expectancy-driven activations <q>(Fiske &amp; Taylor, 1991; Hastie, 1981; Higgins &amp; Bargh, 1987; Stangor &amp; McMillan, 1992)</q>. It seems however impacted by <q>the perceiver's motivation and ability to resolve incongruity (Ruble &amp; Stangor, 1986)</q>. When expectancy disconfirmation occurs, it is commomnly encoded with subcategories, such that the expectancy is globally preserved <q>(e.g., Weber &amp; Crocker, 1983)</q>, thus it does not affect much the overall schema but still remain well memorised.
<strong>Affective consequences</strong>
Although less relevant for intelligence in machines, we can note some interesting points: good-bad judgements relate to attitudes towards specific elements, and such judgements for expectancies can be supported by existing theories described there. Expectancies about self-efficacy also seem both to influence and be influenced by attitudes toward the tasks to perform. Go back to this section for more information.<!-- TODO Use that for a post about value judgement, which is a task in which a machine may perform too and thus gain in expertise -->
<strong>Behavioral consequences</strong>
The chapter develops on several types of consequences, but some are particularly interesting for AI. 
The first one is about hypothesis testing: people may ask whether or not some properties are fulfilled by searching for discriminating information, and they tend to start by asking what they expect the most. However, it may bias the search with <q>positive bias strategy</q>, which focuses on disconfirming what is the most expected to be true only <q>(see Klayman &amp; Ha, 1987; Devine, Hirt, &amp; Gehrke, 1990; Hodgins &amp; Zuckerman, 1993; Skov &amp; Sherman, 1986)</q>. Such a bias should be avoided in AI by favoring proper diagnosticity, although it may be used as a driver for reducing resource consumptions.
Another kind of bias to avoid is the <q>self-fulfilling prophecy (Merton, 1948)</q>: due to one's expectancies, her behaviors might be influenced in such a way that other people react consistently to this expetancy, while forcing her to avoid such a bias may have lead to a different outcome. <q>For reviews and analyses of self-fulfilling prophecies, see Darley and Fazio (1980), Harris and Rosenthal (1985), Hilton and Darley (1991), Jussim (1986, 1991), Miller and Turnbull (1986), Neuberg (1994), Rosenthal and Rubin (1978), and Snyder (1992).</q>
<strong>Physiological consequences</strong>
Although less relevant for intelligence in machines, we can note some interesting points: placebo effects, similarly to self-fulfilling prophecies, tend to confirm expectancies not supposed to be confirmed if the expectancy was not there in the first place, and thus introduce biases. The main difference being that consequences are on the perceiver himself. For machines, we may think about logs showing that a program takes time to compute, while it is actually the logs computation which is done too often and generates most of the load<!-- TODO Bad example, since it is not the machine which adds the logs, but better than nothing as an illustration -->.
<q></q>
<q></q>
<q></q>
<q></q>
<q></q>
</p>

<h3 id="etymology">A Bit of Etymology for Additional Concepts</h3>

<p>
<!-- TODO -->
</p>

<h3 id="formalisation_preparation">Informal Summary Before Proper Formalisation</h3>

<p>
<!-- TODO -->
</p>

<h3 id="preliminary_formalisation">Formal Concepts to Build on</h3>

<p>
<!-- TODO -->
</p>

<h3 id="absolute_formalisation">Formalisation of Absolute Genericness and Specificness</h3>

<p>
<!-- TODO -->
</p>

<h3 id="relative_formalisation">Formalisation of Relative Genericness and Specificness</h3>

<p>
<!-- TODO -->
</p>

<h2 id="answer">Answer</h2>

<p>
<!-- TODO -->
</p>

<!--
<h2 id="links">Related Questions</h2>

&lt;Links to other questions.&gt;
-->

<h2 id="bibliography">Bibliography</h2>

<ul>
<li id="OlsonRoeseZanna1996">
	James M. Olson, Neal J. Roese, and Mark P. Zanna.
	<cite>Expectancies</cite>,
	In Social Psychology: Handbook of Basic Principles, edited by E. Tory Higgins and Arie W. Kruglanski, 211–38. New York: Guilford Press,
	<time datetime="1996">1996</time>.
	ISBN: 978-1-57230-100-9
</li>
</ul>

</body>
</html>